{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/thomas/Downloads/nturgb+d_skeletons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files in the data directory\n",
    "files = os.listdir(data_path)\n",
    "files = [f for f in files if f.endswith('.skeleton')]\n",
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_frames(X):\n",
    "    # Set hip to 0,0,0\n",
    "    for frame in X:\n",
    "        hip_offset = np.concatenate([frame[0][:3], np.zeros(4)])\n",
    "        frame -= hip_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load X from pickle\n",
      "Could not load X and Y, generating them now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Parsed: 100%|██████████| 114480/114480 [16:54<00:00, 112.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Generated, saving to pickle...\n",
      "X Saved to pickle\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load X and Y from pickle before generating them\n",
    "X = {}\n",
    "try:\n",
    "    print('Attempting to load X from pickle')\n",
    "    with open('X.pkl', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    print('X loaded from pickle')\n",
    "except:\n",
    "    print('Could not load X and Y, generating them now')\n",
    "\n",
    "    # Get stats for each file based on name\n",
    "    files_ = []\n",
    "    for file in files:\n",
    "        data = {'file': file,\n",
    "                's': file[0:4],\n",
    "                'c': file[4:8],\n",
    "                'p': file[8:12],\n",
    "                'r': file[12:16],\n",
    "                'a': file[16:20]\n",
    "                }\n",
    "        files_.append(data)\n",
    "\n",
    "    # Generate X and Y\n",
    "    for file_ in tqdm(files_, desc='Files Parsed', position=0):\n",
    "        try:\n",
    "            file = join(data_path, file_['file'])\n",
    "            data = open(file, 'r')\n",
    "            lines = data.readlines()\n",
    "            frames_count = int(lines.pop(0).replace('\\n', ''))\n",
    "            file_['frames'] = frames_count\n",
    "        except UnicodeDecodeError: # .DS_Store file\n",
    "            print('UnicodeDecodeError: ', file)\n",
    "            continue\n",
    "\n",
    "        # Skip file if 2 actors\n",
    "        if lines[0].replace('\\n', '') not in ['1', '2']: continue\n",
    "\n",
    "        # Get P and add to X if not already there\n",
    "        p = file_['file']\n",
    "        if p not in X:\n",
    "            X[p] = []\n",
    "\n",
    "        # Parse the file\n",
    "        for f in tqdm(range(frames_count), desc='Frames Parsed', position=1, leave=False):\n",
    "            try:\n",
    "                # Initiate array to hold frame data\n",
    "                d = []\n",
    "                # Get actor count\n",
    "                actors = int(lines.pop(0).replace('\\n', ''))\n",
    "            \n",
    "                for _ in range(actors):\n",
    "                    # Get actor info\n",
    "                    lines.pop(0)\n",
    "\n",
    "                    # Get joint count\n",
    "                    joint_count = int(lines.pop(0).replace('\\n', ''))\n",
    "\n",
    "                    # Get joint info\n",
    "                    for j in range(joint_count):\n",
    "                        joint = lines.pop(0).replace('\\n', '').split(' ')\n",
    "                        d.append(joint[0:3] + joint[7:11])\n",
    "\n",
    "                # Convert to numpy array\n",
    "                d = np.array(d, dtype=np.float16)\n",
    "\n",
    "                # Append to X and Y\n",
    "                X[p].append(d)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        try:\n",
    "            if len(X[p]) == 0: del X[p]\n",
    "            else: X[p] = normalize_frames(np.array(X[p], dtype=np.float16))\n",
    "        except:\n",
    "            del X[p]\n",
    "\n",
    "    print('X Generated, saving to pickle...')\n",
    "\n",
    "    # Save the data\n",
    "    with open('X.pkl', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    print('X Saved to pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = []\n",
    "label = []\n",
    "performer = []\n",
    "replication = []\n",
    "setup = []\n",
    "\n",
    "for key in X:\n",
    "    setup.append(int(key[1:4]))\n",
    "    camera.append(int(key[5:8]))\n",
    "    performer.append(int(key[9:12]))\n",
    "    replication.append(int(key[13:16]))\n",
    "    label.append(int(key[17:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = set(X.keys())\n",
    "bad_files = set(files) - good_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = sorted(list(good_files))\n",
    "bad_files = sorted(list(bad_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3734, 110746)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_files), len(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera.txt\n",
    "# label.txt\n",
    "# performer.txt\n",
    "# replication.txt\n",
    "# setup.txt\n",
    "# samples_with_missing_skeletons.txt\n",
    "# skes_available_name.txt\n",
    "\n",
    "# Save the data to text files above\n",
    "with open('camera.txt', 'w') as f:\n",
    "    for c in camera:\n",
    "        f.write(str(c) + '\\n')\n",
    "\n",
    "with open('label.txt', 'w') as f:\n",
    "    for l in label:\n",
    "        f.write(str(l) + '\\n')\n",
    "\n",
    "with open('performer.txt', 'w') as f:\n",
    "    for p in performer:\n",
    "        f.write(str(p) + '\\n')\n",
    "\n",
    "with open('replication.txt', 'w') as f:\n",
    "    for r in replication:\n",
    "        f.write(str(r) + '\\n')\n",
    "\n",
    "with open('setup.txt', 'w') as f:\n",
    "    for s in setup:\n",
    "        f.write(str(s) + '\\n')\n",
    "\n",
    "with open('samples_with_missing_skeletons.txt', 'w') as f:\n",
    "    for s in bad_files:\n",
    "        f.write(s + '\\n')\n",
    "\n",
    "with open('skes_available_name.txt', 'w') as f:\n",
    "    for s in good_files:\n",
    "        f.write(s + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
